import json
from datetime import datetime

print("=" * 80)
print("AGENT 4: ADVANCED INSIGHT GENERATOR")
print("=" * 80)

def insight_generator_agent(fact_check_data, summarization_data):
    """
    Agent 4: Advanced Insight Generator
    Analyzes processed research to identify trends, gaps, comparative findings, 
    and future research directions using advanced prompting techniques.
    
    Uses Chain-of-Thought, Few-Shot Learning, and Structured Reasoning.
    
    Args:
        fact_check_data: Validated summaries from Fact-Check Agent
        summarization_data: Summary data for additional context
    
    Returns:
        Comprehensive insights with trend analysis and research recommendations
    """
    print(f"\nüí° Starting Advanced Insight Generator Agent...")
    print(f"Received data from: {fact_check_data['agent']}")
    print(f"Analyzing {fact_check_data['papers_validated']} validated papers\n")
    
    insight_generator_output = {
        'agent': 'Advanced Insight Generator',
        'timestamp': datetime.now().isoformat(),
        'input_agent': fact_check_data['agent'],
        'papers_analyzed': fact_check_data['papers_validated'],
        'paper_insights': [],
        'trend_analysis': {},
        'gap_analysis': {},
        'comparative_findings': {},
        'future_research_directions': []
    }
    
    # ========================================================================
    # STEP 1: Per-Paper Deep Analysis with Chain-of-Thought Reasoning
    # ========================================================================
    print(f"\n{'=' * 80}")
    print("STEP 1: PER-PAPER DEEP ANALYSIS (Chain-of-Thought)")
    print("=" * 80)
    
    all_topics = []
    all_relevance_scores = []
    all_implications = []
    topic_frequency = {}
    
    for validation in fact_check_data['validated_summaries']:
        print(f"\n{'‚îÄ' * 80}")
        print(f"üìÑ Analyzing Paper {validation['paper_id']}: {validation['title'][:60]}...")
        
        # Find corresponding summary for additional context
        summary_data = next(s for s in summarization_data['summaries'] if s['paper_id'] == validation['paper_id'])
        
        # Chain-of-Thought: Structured multi-step reasoning
        paper_insight = {
            'paper_id': validation['paper_id'],
            'title': validation['title'],
            'verification_status': validation['verification_status'],
            'relevance_score': validation['relevance_score'],
            'topic_overlap': validation['topic_overlap_ratio'],
            'claimed_topics': validation['claimed_topics'],
            'reasoning_chain': {},
            'key_insights': [],
            'research_implications': [],
            'contribution_type': None,
            'maturity_level': None
        }
        
        # Chain-of-Thought Step 1: Assess research contribution type
        print(f"   üîç Reasoning Step 1: Identifying contribution type...")
        if 'meta-analysis' in validation['title'].lower():
            paper_insight['contribution_type'] = 'Meta-Study/Review'
            paper_insight['reasoning_chain']['contribution'] = "Meta-analysis indicates comprehensive literature review and synthesis"
        elif any(term in validation['title'].lower() for term in ['novel', 'new', 'introducing']):
            paper_insight['contribution_type'] = 'Novel Method/Innovation'
            paper_insight['reasoning_chain']['contribution'] = "Language suggests introduction of new methodology or approach"
        elif any(term in validation['title'].lower() for term in ['application', 'implementing', 'clinical']):
            paper_insight['contribution_type'] = 'Applied Research'
            paper_insight['reasoning_chain']['contribution'] = "Focus on practical application in real-world settings"
        else:
            paper_insight['contribution_type'] = 'Empirical Study'
            paper_insight['reasoning_chain']['contribution'] = "Empirical research advancing understanding in specific domain"
        
        # Chain-of-Thought Step 2: Assess research maturity
        print(f"   üîç Reasoning Step 2: Evaluating research maturity...")
        if validation['verification_status'] == 'VERIFIED' and validation['relevance_score'] > 0.18:
            paper_insight['maturity_level'] = 'High - Ready for Citation'
            paper_insight['reasoning_chain']['maturity'] = f"Verified status + high relevance ({validation['relevance_score']:.4f}) = citation-ready"
        elif validation['verification_status'] == 'VERIFIED':
            paper_insight['maturity_level'] = 'Medium - Needs Context'
            paper_insight['reasoning_chain']['maturity'] = "Verified but moderate relevance - use with additional context"
        else:
            paper_insight['maturity_level'] = 'Low - Further Validation Needed'
            paper_insight['reasoning_chain']['maturity'] = "Requires additional validation before use"
        
        # Chain-of-Thought Step 3: Extract key insights
        print(f"   üîç Reasoning Step 3: Extracting insights...")
        if validation['topic_overlap_ratio'] >= 0.9:
            insight = f"Core alignment: {validation['topic_overlap_ratio']:.0%} topic match indicates central relevance"
            paper_insight['key_insights'].append(insight)
        
        if validation['verification_status'] == 'VERIFIED':
            paper_insight['key_insights'].append(
                f"High credibility: All claims verified against knowledge base"
            )
        
        if validation['relevance_score'] > 0.18:
            paper_insight['key_insights'].append(
                f"Strong semantic relevance (score: {validation['relevance_score']:.4f}) - highly relevant to research queries"
            )
        elif validation['relevance_score'] < 0.10:
            paper_insight['key_insights'].append(
                f"Tangential relevance (score: {validation['relevance_score']:.4f}) - peripheral to main focus"
            )
        
        # Chain-of-Thought Step 4: Derive research implications
        print(f"   üîç Reasoning Step 4: Deriving implications...")
        topic_implication_map = {
            'deep learning': {
                'implication': 'Foundation for advanced pattern recognition and automated feature extraction',
                'application': 'Applicable to complex medical image analysis tasks'
            },
            'machine learning': {
                'implication': 'Data-driven modeling for predictive and diagnostic systems',
                'application': 'Enables automated decision support with continuous learning'
            },
            'clinical decision support': {
                'implication': 'Direct patient care enhancement through evidence-based recommendations',
                'application': 'Measurable impact on clinical outcomes and treatment efficacy'
            },
            'natural language processing': {
                'implication': 'Unstructured clinical data becomes analyzable and actionable',
                'application': 'Extracts insights from physician notes, reports, and literature'
            },
            'medical imaging': {
                'implication': 'Computer vision techniques enhance diagnostic accuracy',
                'application': 'Reduces radiologist workload while improving detection rates'
            },
            'electronic health records': {
                'implication': 'Structured and unstructured EHR data integration',
                'application': 'Comprehensive patient profiles for personalized medicine'
            }
        }
        
        for topic in validation['claimed_topics']:
            if topic in topic_implication_map:
                impl_data = topic_implication_map[topic]
                paper_insight['research_implications'].append(
                    f"{topic.upper()}: {impl_data['implication']} ‚Üí {impl_data['application']}"
                )
                all_implications.append(impl_data)
        
        # Track topics for trend analysis
        all_topics.extend(validation['claimed_topics'])
        for topic in validation['claimed_topics']:
            topic_frequency[topic] = topic_frequency.get(topic, 0) + 1
        
        all_relevance_scores.append(validation['relevance_score'])
        
        insight_generator_output['paper_insights'].append(paper_insight)
        
        print(f"   ‚úì Contribution: {paper_insight['contribution_type']}")
        print(f"   ‚úì Maturity: {paper_insight['maturity_level']}")
        print(f"   ‚úì Key insights: {len(paper_insight['key_insights'])}")
        print(f"   ‚úì Implications: {len(paper_insight['research_implications'])}")
    
    # ========================================================================
    # STEP 2: Trend Analysis with Few-Shot Pattern Recognition
    # ========================================================================
    print(f"\n{'=' * 80}")
    print("STEP 2: TREND ANALYSIS (Few-Shot Pattern Recognition)")
    print("=" * 80)
    
    unique_topics = set(all_topics)
    avg_relevance = sum(all_relevance_scores) / len(all_relevance_scores)
    verification_rate = fact_check_data['validation_metrics']['verification_rate']
    
    print(f"\nüìä Trend Identification Patterns:")
    print(f"   Pattern 1: Topic clustering ‚Üí Identify dominant themes")
    print(f"   Pattern 2: Frequency analysis ‚Üí Detect emerging vs established areas")
    print(f"   Pattern 3: Cross-paper connections ‚Üí Find research synergies")
    
    # Dominant topics (appear in >50% of papers)
    dominant_topics = [topic for topic, freq in topic_frequency.items() 
                       if freq / len(fact_check_data['validated_summaries']) > 0.5]
    
    # Emerging topics (appear in 1 paper only)
    emerging_topics = [topic for topic, freq in topic_frequency.items() if freq == 1]
    
    insight_generator_output['trend_analysis'] = {
        'total_unique_topics': len(unique_topics),
        'topic_diversity_score': len(unique_topics) / (len(all_topics) + 1),  # normalized
        'topic_frequency_map': topic_frequency,
        'dominant_themes': dominant_topics,
        'emerging_areas': emerging_topics,
        'average_relevance': round(avg_relevance, 4),
        'verification_quality': verification_rate,
        'identified_trends': []
    }
    
    # Trend 1: Methodological trends
    if any(ml_topic in unique_topics for ml_topic in ['deep learning', 'machine learning', 'CNN']):
        insight_generator_output['trend_analysis']['identified_trends'].append({
            'trend': 'AI/ML Dominance',
            'description': 'AI and machine learning methods are primary methodological approach across research corpus',
            'evidence': f"{len([t for t in all_topics if t in ['deep learning', 'machine learning', 'CNN']])} mentions across {len(fact_check_data['validated_summaries'])} papers",
            'implication': 'Future research will likely continue leveraging AI/ML frameworks'
        })
    
    # Trend 2: Application domain trends
    if any(app_topic in unique_topics for app_topic in ['clinical decision support', 'medical imaging', 'electronic health records']):
        insight_generator_output['trend_analysis']['identified_trends'].append({
            'trend': 'Healthcare Application Focus',
            'description': 'Strong emphasis on practical healthcare applications and clinical deployment',
            'evidence': f"{len([t for t in all_topics if t in ['clinical decision support', 'medical imaging', 'electronic health records']])} healthcare-specific topics identified",
            'implication': 'Research is transitioning from theory to clinical practice implementation'
        })
    
    # Trend 3: Diversity and breadth
    if len(unique_topics) >= 8:
        insight_generator_output['trend_analysis']['identified_trends'].append({
            'trend': 'Interdisciplinary Integration',
            'description': f'High topic diversity ({len(unique_topics)} unique topics) indicates interdisciplinary research approach',
            'evidence': f"Topics span {len(dominant_topics)} dominant themes and {len(emerging_topics)} emerging areas",
            'implication': 'Research benefits from cross-domain knowledge integration'
        })
    
    # Trend 4: Research quality
    if verification_rate >= 0.9:
        insight_generator_output['trend_analysis']['identified_trends'].append({
            'trend': 'High Verification Quality',
            'description': f'{verification_rate:.0%} verification rate indicates rigorous, evidence-based research',
            'evidence': f"{int(verification_rate * len(fact_check_data['validated_summaries']))} of {len(fact_check_data['validated_summaries'])} papers fully verified",
            'implication': 'Research corpus is suitable for meta-analysis and systematic review'
        })
    
    print(f"\n   ‚úì Identified trends: {len(insight_generator_output['trend_analysis']['identified_trends'])}")
    print(f"   ‚úì Dominant themes: {len(dominant_topics)}")
    print(f"   ‚úì Emerging areas: {len(emerging_topics)}")
    
    # ========================================================================
    # STEP 3: Gap Analysis with Comparative Reasoning
    # ========================================================================
    print(f"\n{'=' * 80}")
    print("STEP 3: GAP ANALYSIS (Comparative Reasoning)")
    print("=" * 80)
    
    print(f"\nüîç Comparative Analysis Framework:")
    print(f"   Compare: Expected vs Observed coverage")
    print(f"   Identify: Missing perspectives and underexplored areas")
    print(f"   Recommend: Priority areas for future investigation")
    
    # Expected topics in AI healthcare research
    expected_healthcare_ai_topics = {
        'deep learning', 'machine learning', 'natural language processing',
        'clinical decision support', 'medical imaging', 'electronic health records',
        'predictive modeling', 'patient outcomes', 'data privacy', 'model interpretability',
        'real-time systems', 'regulatory compliance', 'clinical validation',
        'transfer learning', 'federated learning'
    }
    
    covered_topics = unique_topics
    missing_topics = expected_healthcare_ai_topics - covered_topics
    
    # Identify research gaps
    research_gaps = []
    
    if 'model interpretability' in missing_topics or 'explainable AI' not in all_topics:
        research_gaps.append({
            'gap_type': 'Methodological Gap',
            'description': 'Limited coverage of model interpretability and explainability',
            'severity': 'High',
            'rationale': 'Healthcare AI requires transparent decision-making for clinical adoption',
            'recommendation': 'Include research on explainable AI methods and interpretation techniques'
        })
    
    if 'data privacy' in missing_topics or 'federated learning' in missing_topics:
        research_gaps.append({
            'gap_type': 'Privacy & Security Gap',
            'description': 'Insufficient focus on data privacy and federated learning approaches',
            'severity': 'Medium-High',
            'rationale': 'Patient data protection is critical for healthcare AI deployment',
            'recommendation': 'Incorporate privacy-preserving ML and federated learning research'
        })
    
    if 'clinical validation' in missing_topics or 'patient outcomes' in missing_topics:
        research_gaps.append({
            'gap_type': 'Validation Gap',
            'description': 'Limited emphasis on clinical validation and patient outcome measurement',
            'severity': 'Medium',
            'rationale': 'Real-world effectiveness must be demonstrated beyond technical metrics',
            'recommendation': 'Include clinical trial results and longitudinal outcome studies'
        })
    
    if 'transfer learning' in missing_topics:
        research_gaps.append({
            'gap_type': 'Generalization Gap',
            'description': 'Sparse coverage of transfer learning and domain adaptation',
            'severity': 'Medium',
            'rationale': 'Models must generalize across different clinical settings and populations',
            'recommendation': 'Explore transfer learning for cross-institutional model deployment'
        })
    
    insight_generator_output['gap_analysis'] = {
        'expected_topics': list(expected_healthcare_ai_topics),
        'covered_topics': list(covered_topics),
        'missing_topics': list(missing_topics),
        'coverage_rate': len(covered_topics.intersection(expected_healthcare_ai_topics)) / len(expected_healthcare_ai_topics),
        'identified_gaps': research_gaps
    }
    
    print(f"\n   ‚úì Coverage rate: {insight_generator_output['gap_analysis']['coverage_rate']:.1%}")
    print(f"   ‚úì Identified gaps: {len(research_gaps)}")
    print(f"   ‚úì Missing topics: {len(missing_topics)}")
    
    # ========================================================================
    # STEP 4: Comparative Findings
    # ========================================================================
    print(f"\n{'=' * 80}")
    print("STEP 4: COMPARATIVE FINDINGS")
    print("=" * 80)
    
    # Compare papers by contribution type
    contribution_types = {}
    for paper in insight_generator_output['paper_insights']:
        ctype = paper['contribution_type']
        if ctype not in contribution_types:
            contribution_types[ctype] = []
        contribution_types[ctype].append({
            'paper_id': paper['paper_id'],
            'title': paper['title'],
            'relevance': paper['relevance_score']
        })
    
    # Compare papers by maturity level
    maturity_distribution = {}
    for paper in insight_generator_output['paper_insights']:
        mlevel = paper['maturity_level']
        maturity_distribution[mlevel] = maturity_distribution.get(mlevel, 0) + 1
    
    insight_generator_output['comparative_findings'] = {
        'by_contribution_type': contribution_types,
        'by_maturity_level': maturity_distribution,
        'relevance_comparison': {
            'highest_relevance': max(all_relevance_scores),
            'lowest_relevance': min(all_relevance_scores),
            'relevance_range': max(all_relevance_scores) - min(all_relevance_scores),
            'average': avg_relevance
        },
        'key_comparisons': []
    }
    
    # Key comparison 1: Relevance consistency
    if max(all_relevance_scores) - min(all_relevance_scores) < 0.1:
        insight_generator_output['comparative_findings']['key_comparisons'].append({
            'finding': 'Consistent Relevance Scores',
            'description': f'Low variance in relevance ({max(all_relevance_scores) - min(all_relevance_scores):.4f}) indicates cohesive research focus',
            'implication': 'Papers form unified corpus suitable for comprehensive review'
        })
    else:
        insight_generator_output['comparative_findings']['key_comparisons'].append({
            'finding': 'Variable Relevance Scores',
            'description': f'Higher variance ({max(all_relevance_scores) - min(all_relevance_scores):.4f}) suggests diverse perspectives',
            'implication': 'Consider filtering by relevance threshold for focused analysis'
        })
    
    # Key comparison 2: Contribution diversity
    if len(contribution_types) >= 3:
        insight_generator_output['comparative_findings']['key_comparisons'].append({
            'finding': 'Diverse Contribution Types',
            'description': f'{len(contribution_types)} different contribution types present',
            'implication': 'Corpus includes both theoretical foundations and practical applications'
        })
    
    print(f"\n   ‚úì Contribution types: {len(contribution_types)}")
    print(f"   ‚úì Maturity levels: {len(maturity_distribution)}")
    print(f"   ‚úì Key comparisons: {len(insight_generator_output['comparative_findings']['key_comparisons'])}")
    
    # ========================================================================
    # STEP 5: Future Research Directions
    # ========================================================================
    print(f"\n{'=' * 80}")
    print("STEP 5: FUTURE RESEARCH DIRECTIONS")
    print("=" * 80)
    
    future_directions = []
    
    # Direction 1: Based on identified gaps
    for gap in research_gaps:
        future_directions.append({
            'direction': f"Address {gap['gap_type']}",
            'priority': gap['severity'],
            'description': gap['recommendation'],
            'rationale': gap['rationale'],
            'expected_impact': 'High - Fills critical knowledge gap in current research landscape'
        })
    
    # Direction 2: Based on emerging topics
    if emerging_topics:
        future_directions.append({
            'direction': 'Expand Emerging Research Areas',
            'priority': 'Medium',
            'description': f"Deepen investigation into: {', '.join(emerging_topics[:3])}",
            'rationale': 'These areas show initial promise but need more comprehensive study',
            'expected_impact': 'Medium - Potential for breakthrough insights in underexplored domains'
        })
    
    # Direction 3: Based on dominant themes
    if dominant_topics:
        future_directions.append({
            'direction': 'Advanced Integration Studies',
            'priority': 'High',
            'description': f"Combine dominant themes ({', '.join(dominant_topics)}) in integrated systems",
            'rationale': 'Leverage strengths of established areas for comprehensive solutions',
            'expected_impact': 'High - Practical, deployable systems combining proven methodologies'
        })
    
    # Direction 4: Cross-domain opportunities
    future_directions.append({
        'direction': 'Cross-Domain Knowledge Transfer',
        'priority': 'Medium-High',
        'description': 'Apply successful methods from one healthcare domain to others',
        'rationale': f'With {len(unique_topics)} distinct topics, opportunities exist for knowledge transfer',
        'expected_impact': 'Medium-High - Accelerates progress through adapted proven solutions'
    })
    
    # Direction 5: Methodological advancement
    if verification_rate == 1.0:
        future_directions.append({
            'direction': 'Advanced Methodological Research',
            'priority': 'Medium',
            'description': 'Build on solid foundation with next-generation methods',
            'rationale': 'High verification quality enables confident advancement of state-of-the-art',
            'expected_impact': 'High - Push boundaries of what\'s technically achievable'
        })
    
    insight_generator_output['future_research_directions'] = future_directions
    
    print(f"\n   ‚úì Future directions identified: {len(future_directions)}")
    print(f"   ‚úì High priority directions: {len([d for d in future_directions if 'High' in d['priority']])}")
    print(f"   ‚úì Medium priority directions: {len([d for d in future_directions if 'Medium' in d['priority']])}")
    
    # ========================================================================
    # FINAL SUMMARY
    # ========================================================================
    print(f"\n{'=' * 80}")
    print(f"‚úÖ Advanced Insight Generator Agent Complete")
    print(f"=" * 80)
    print(f"   ‚Ä¢ Papers analyzed: {len(insight_generator_output['paper_insights'])}")
    print(f"   ‚Ä¢ Trends identified: {len(insight_generator_output['trend_analysis']['identified_trends'])}")
    print(f"   ‚Ä¢ Research gaps: {len(insight_generator_output['gap_analysis']['identified_gaps'])}")
    print(f"   ‚Ä¢ Comparative findings: {len(insight_generator_output['comparative_findings']['key_comparisons'])}")
    print(f"   ‚Ä¢ Future directions: {len(insight_generator_output['future_research_directions'])}")
    print(f"=" * 80)
    
    return insight_generator_output

# Execute Advanced Insight Generator Agent
insight_generator_output = insight_generator_agent(fact_check_output, summarization_output)

print(f"\n\nüìä ADVANCED INSIGHT GENERATOR OUTPUT SUMMARY")
print(f"{'=' * 80}")
print(json.dumps({
    'agent': insight_generator_output['agent'],
    'papers_analyzed': insight_generator_output['papers_analyzed'],
    'trends_identified': len(insight_generator_output['trend_analysis']['identified_trends']),
    'research_gaps': len(insight_generator_output['gap_analysis']['identified_gaps']),
    'comparative_findings': len(insight_generator_output['comparative_findings']['key_comparisons']),
    'future_directions': len(insight_generator_output['future_research_directions']),
    'coverage_rate': f"{insight_generator_output['gap_analysis']['coverage_rate']:.1%}",
    'timestamp': insight_generator_output['timestamp']
}, indent=2))

print(f"\nüíæ Data structure ready for next agent: 'insight_generator_output'")
print(f"   Keys: {list(insight_generator_output.keys())}")